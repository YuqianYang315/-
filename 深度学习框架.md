import os
import torch.utils.data import Dataset,Dataloader
import torch
import torch.nn as nn
from sklearn.metrics import f1_score
# 1数据预处理
## 1.1 torch基础方法
### 1.1.1 数据datasets
```
class Mydatasets(Dataset):
    def __init__(self):
        #传入data和target路径，进行读取以获得文件，这里可以将文件路径存入config中。
        pass
    def __getitem__(self, index):
        #对数据在这里进行处理：分词，取最大长度等
        #返回形式一般为input,target,input_len/input2index,target_len/target2index,根据任务看返回什么比较方便
        pass
    def __len__(self):
        #return len(self.input_lines)
        pass
```
### 1.1.2 dataloader（），将dataset实例化其中
```
train_dataloader = DataLoader(MyDataset(),batch_size=myconfig.chatbot_batch_size,shuffle=True,collate_fn=collate_fn,drop_last=True)
```
如果已经按照长度进行排序则不进行shuffle
对于collate_fn可以进行基于batchsize大小的数据排序，word2id，以及将
 [(input,target,input_len,target_len),(input,target,input_len,target_len)......]的数据变成---->
 [(input1,input2,...),(target1,target2,...),(input_len1,input_len2,...),(target_len1,target_len2,...)]

## 1.2 torchtext


# 2 dataloader

# 3 model  

# 4 optim

# 5 train

# 6 eval

